{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File:2 Machine Learning and Prediction\n",
    "\n",
    "# Notebook Structure\n",
    "\n",
    "1. Pre-requisite for File2\n",
    "2. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-requisite for File2\n",
    "\n",
    "#### Pre-requisite Libraries to be installed to setup environment:\n",
    "`pip install seaborn`<br>\n",
    "`pip install pandas`<br>\n",
    "`pip install numpy`<br>\n",
    "`pip install category_encoders`<br>\n",
    "`pip install matplotlib`<br>\n",
    "`pip install DateTime`<br>\n",
    "`pip install seaborn`<br>\n",
    "`pip install sklearn`<br>\n",
    "`pip install statsmodels`<br>\n",
    "`pip install scipy`<br>\n",
    "`pip install flask`<br>\n",
    "`pip install flask_restful`<br>\n",
    "\n",
    "### `File1 (Group7_File1_DataValidation_and_Preprocessing.ipyb) has to be executed for File2 to run successfully.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                       # dataframes \n",
    "import numpy as np  \n",
    "import datetime as dt\n",
    "from seaborn import load_dataset                          # Titanic dataset\n",
    "from sklearn.cluster import KMeans                        # k-means clustering \n",
    "from sklearn.model_selection import train_test_split      # train/test data\n",
    "from sklearn.neighbors import KNeighborsClassifier        # k-NN classification \n",
    "from sklearn.linear_model import LogisticRegression       # logistic regression \n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    " \n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the output dataset from data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "df = pd.read_csv('data/merged_data.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Create a funtion to return discount value if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row['PRICE'] < row['BASE_PRICE']:\n",
    "        val = abs(row['PRICE'] - row['BASE_PRICE'])\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the funtion to the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column  \n",
    "df['DISCOUNTVALUE'] = df.apply(f, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop features that are not impactful for prediction. \n",
    "Removing redundant variables as they wont add value to the model and large feature subsets may actually reduce the performance of some machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['WEEK_END_DATE', 'SUB_CATEGORY','PRICE',\n",
    "            'PRODUCT_WEIGHT_LB',\n",
    "            'SEG_VALUE_NAME','MSA_CODE','ADDRESS_STATE_PROV_CODE'\n",
    "           ]\n",
    "           , axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create numerical variables for the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MANUFACTURER = pd.Categorical(df.MANUFACTURER)\n",
    "df.MANUFACTURER = df.MANUFACTURER.cat.codes\n",
    "\n",
    "df.CATEGORY = pd.Categorical(df.CATEGORY)\n",
    "df.CATEGORY = df.CATEGORY.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning wont work if there are null values in the data set. So verifying for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining features and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['PRODUCT_ID','FEATURE','WEEKOFYEAR',\n",
    "            'DISPLAY','MANUFACTURER','CATEGORY' ,\n",
    "            'BASE_PRICE',\n",
    "            'DISCOUNTVALUE'\n",
    "            ,'STORE_ID'\n",
    "            ,'AVG_WEEKLY_ORDERS'\n",
    "            ,'SALES_AREA_SIZE_NUM',\n",
    "           ]\n",
    "target = 'UNITS'\n",
    "\n",
    "features, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train and test data with 75-25 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Scores on train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## score for linear regression is the R2\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "print(lr.score(X_test, y_test))\n",
    "\n",
    "preds = lr.predict(X_test)\n",
    "\n",
    "score = explained_variance_score(y_test, preds)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, preds))\n",
    "r2 = r2_score(y_test, preds)\n",
    "    \n",
    "print(\"score = {:.5f} | MAE = {:.3f} | RMSE = {:.3f} | R2 = {:.5f}\"\n",
    "          .format(score, mae, rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = sm.add_constant(X_test)\n",
    "est = sm.OLS(y_test, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr(method ='pearson') \n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression feature importance\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get importance\n",
    "importance = lr.coef_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([X_train for X_train in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stats of the model show there are no P values for the set of features used.\n",
    "The feature importance values for each of the column used is analysed to find which feature used affects the sales.\n",
    "The result of feature importance check is below:\n",
    "\n",
    "<pre>\n",
    "PRODUCT_ID \t\t\t Feature: 0, Score: -0.00000\n",
    "FEATURE \t\t\t\tFeature: 1, Score: 19.50686\n",
    "WEEKOFYEAR \t\t\t Feature: 2, Score: -0.00667\n",
    "DISPLAY\t\t\t\t Feature: 3, Score: 24.92311\n",
    "MANUFACTURER\t\t\tFeature: 4, Score: 2.38433\n",
    "CATEGORY\t\t\t\tFeature: 5, Score: 10.63296\n",
    "BASE_PRICE\t\t\t  Feature: 6, Score: -0.09663\n",
    "DISCOUNTVALUE\t\t   Feature: 7, Score: 0.09853\n",
    "STORE_ID\t\t\t\tFeature: 8, Score: -0.00010\n",
    "AVG_WEEKLY_ORDERS\t   Feature: 9, Score: 0.00531\n",
    "SALES_AREA_SIZE_NUM     Feature: 10, Score: 0.00041\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference from the feature importance analysis** <br>\n",
    "- Display has a high impact on sales i.e., an item on the display at dealer store is more likely to sell.\n",
    "- Feature affects the sales or featured products are most likely to sell.\n",
    "- Category is the third most important feature that affects sales.\n",
    "- The fourth most important feature is Manufacturer which is also the brand of the product.\n",
    "- There is no evidence for the rest of features having significant impact on sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying prediction: \n",
    "Predict for a product and store combination for year 2020, 16th week with other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1 = { \n",
    "\"PRODUCT_ID\":1111009497,\n",
    "\"FEATURE\":0,\n",
    "\"WEEKOFYEAR\":202016,\n",
    "\"DISPLAY\":0,\n",
    "\"MANUFACTURER\":0,\n",
    "\"CATEGORY\" :1,\n",
    "\"BASE_PRICE\":122,\n",
    "\"DISCOUNTVALUE\":100,\n",
    "\"STORE_ID\":367,\n",
    "\"AVG_WEEKLY_ORDERS\":1155,\n",
    "\"SALES_AREA_SIZE_NUM\":24721\n",
    " }\n",
    "\n",
    "X_new = []  # X_new contains new data items \n",
    "\n",
    "for obs in [product1]:\n",
    "    new_obs = [obs[\"PRODUCT_ID\"],\n",
    "               obs[\"FEATURE\"], \n",
    "               obs[\"WEEKOFYEAR\"], \n",
    "               obs[\"DISPLAY\"], \n",
    "               obs[\"MANUFACTURER\"], \n",
    "               obs[\"CATEGORY\"], \n",
    "               obs[\"BASE_PRICE\"], \n",
    "               obs[\"DISCOUNTVALUE\"] ,\n",
    "               obs[\"STORE_ID\"],\n",
    "               obs[\"AVG_WEEKLY_ORDERS\"],\n",
    "               obs[\"SALES_AREA_SIZE_NUM\"] \n",
    "              ]\n",
    "    X_new.append(new_obs)\n",
    "    \n",
    "\n",
    "lr.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pikle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "with open (\"models/group7regressionmodel.pkl\",\"wb\") as fwb:\n",
    "    joblib.dump(lr,fwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results and Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal was to forecast/predict demand of various products for the next week for different dealers. The data set received are validated and carefully analysed to arrive at some important inferences in the `Data Validation`, `Exploration`,`Preprocessing` steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data received contains more columns that does not add value to the model. Some columns like dealer name, product description, address of dealer including city, state , MSA code, parking capacity are found in the data file. They are only additional information but does not add value to the model and these features are removed from the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform prediction for a given week, we need a year and week variable for ease of input and handling. The `WEEK_END_DATE` column has been transformed to `WEEKOFYEAR` to hold only year and week number (i.e. 202001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly a new variable for `DISCOUNTVALUE` is created based on `BASE_PRICE` and `PRICE` variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Linear regression model is build over the data set defining the features and target variable(UNITS).\n",
    "\n",
    "#### Below variables are considered as features in the linear regression prediction\n",
    "- PRODUCT_ID\n",
    "- FEATURE\n",
    "- WEEKOFYEAR\n",
    "- DISPLAY\n",
    "- MANUFACTURER\n",
    "- CATEGORY\n",
    "- BASE_PRICE\n",
    "- DISCOUNTVALUE\n",
    "- STORE_ID\n",
    "- AVG_WEEKLY_ORDERS\n",
    "- SALES_AREA_SIZE_NUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To run the Flask app we need the below inputs in order.\n",
    "PRODUCT_ID<br>FEATURE<br>WEEKOFYEAR<br>DISPLAY<br>MANUFACTURER<br>CATEGORY<br>ADDRESS_STATE_PROV_CODE<br>BASE_PRICE<br>DISCOUNTAVAILABLE<br>STORE_ID<br>AVG_WEEKLY_ORDERS<br>SALES_AREA_SIZE_NUM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
